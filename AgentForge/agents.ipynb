{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3883f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Collecting packaging<25,>=23.2 (from langchainhub)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\gauravkumar743\\desktop\\langchain\\venv\\lib\\site-packages (from langchainhub) (2.32.5)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gauravkumar743\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gauravkumar743\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gauravkumar743\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gauravkumar743\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2025.10.5)\n",
      "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: types-requests, packaging, langchainhub\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed langchainhub-0.1.21 packaging-24.2 types-requests-2.32.4.20250913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ! pip install arxiv\n",
    "# ! pip install wikipedia\n",
    "! pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "009db4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "164cad46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000021179B52870>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000021179B571A0>, root_client=<openai.OpenAI object at 0x0000021179B52D20>, root_async_client=<openai.AsyncOpenAI object at 0x0000021179B52B40>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o\",temperature=0)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a984d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39cff68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=10,doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0648fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54d15dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'LangSmith docs - Docs by LangChain', 'language': 'en'}, page_content=\"LangSmith docs - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangSmithSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangSmith docsGet startedObservabilityEvaluationPrompt engineeringDeploymentHostingAgent BuilderOverviewPlansCreate an account and API keyAccount administrationOverviewSet up a workspaceManage organizations using the APIManage billingSet up resource tagsUser managementReferenceLangSmith Python SDKLangSmith JS/TS SDKLangGraph Python SDKLangGraph JS/TS SDKLangSmith APIAPI reference for LangSmith DeploymentAdditional resourcesReleases & changelogsData managementAuthentication methodsFAQsRegions FAQPricing FAQLangSmith docsCopy pageCopy pageLangSmith provides tools for developing, debugging, and deploying LLM applications.\\nIt helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\\nLangSmith is framework agnostic, so you can use it with or without LangChain’s open-source libraries\\nlangchain and langgraph.\\nPrototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems.\\nLangGraph Platform is now LangSmith Deployment. For more information, check out the Changelog.\\n\\u200bGet started\\nCreate an accountSign up at smith.langchain.com (no credit card required).\\nYou can log in with Google, GitHub, or email.Create an API keyGo to your Settings page → API Keys → Create API Key.\\nCopy the key and save it securely.\\nOnce your account and API key are ready, choose a quickstart to begin building with LangSmith:\\nObservabilityGain visibility into every step your application takes to debug faster and improve reliability.Start tracingEvaluationMeasure and track quality over time to ensure your AI applications are consistent and trustworthy.Evaluate your appDeploymentDeploy your agents as LangGraph Servers, ready to scale in production.Deploy your agentsPrompt TestingIterate on prompts with built-in versioning and collaboration to ship improvements faster.Test your promptsStudioUse a visual interface to design, test, and refine applications end-to-end.Develop with StudioHostingHost LangSmith in the cloud, in your environment, or hybrid to match your infrastructure and compliance needs.Choose your hosting mode\\n\\u200bWorkflow\\nLangSmith combines observability, evaluation, deployment, and hosting in one integrated workflow—from local development to production.\\n\\n\\n\\nEdit the source of this page on GitHub.\\nConnect these docs programmatically to Claude, VSCode, and more via MCP for    real-time answers.Was this page helpful?YesNoPricing plansNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\")]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002111E5E2660>, search_kwargs={})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "print(docs)\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents,OpenAIEmbeddings())\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fef69ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='langsmith', description='Search for langsmith. For any question about langsmith, you must use this tool.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000211790A7880>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002111E5E2660>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000211790A79C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002111E5E2660>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever,\"langsmith\",\n",
    "                                       \"Search for langsmith. For any question about langsmith, you must use this tool.\")\n",
    "\n",
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7cb9f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arxiv\n",
    "\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper = arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5de4524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\gauravkumar743\\\\Desktop\\\\Langchain\\\\venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=10, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='langsmith', description='Search for langsmith. For any question about langsmith, you must use this tool.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000211790A7880>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002111E5E2660>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000211790A79C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002111E5E2660>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " Combine all the 3 tools:\n",
    " 1. Wikipedia\n",
    " 2. Langsmith - retrieval tool\n",
    " 3. Arxiv\n",
    " \"\"\"\n",
    "\n",
    "tools = [wiki,retriever_tool,arxiv]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1cbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75f15976",
   "metadata": {},
   "source": [
    "Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a619c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "\n",
    "# prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "# prompt.messages\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7637220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent and let the llm know about the tools it can access.\n",
    "\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba05361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent executor\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b217de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'self-attention mechanism'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Attention Is All You Need\n",
      "Summary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new de\u001b[0m\u001b[32;1m\u001b[1;3mThe self-attention mechanism is a key component introduced in the 2017 research paper \"Attention Is All You Need\" by researchers at Google. This mechanism is fundamental to the architecture of the Transformer model, which has become a cornerstone in the field of machine learning, particularly in natural language processing tasks. The self-attention mechanism allows the model to weigh the importance of different words in a sentence when encoding a sequence, enabling it to capture dependencies and relationships between words more effectively than previous models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is self attention mechanism?',\n",
       " 'output': 'The self-attention mechanism is a key component introduced in the 2017 research paper \"Attention Is All You Need\" by researchers at Google. This mechanism is fundamental to the architecture of the Transformer model, which has become a cornerstone in the field of machine learning, particularly in natural language processing tasks. The self-attention mechanism allows the model to weigh the importance of different words in a sentence when encoding a sequence, enabling it to capture dependencies and relationships between words more effectively than previous models.'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Who is self attention mechanism?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c4033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
